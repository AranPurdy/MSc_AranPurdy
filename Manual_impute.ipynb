{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a920b54d-282e-4359-b061-716e7b11536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration Loaded ---\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 1: CONFIGURATION\n",
    "# This cell contains all the settings a user needs to change.\n",
    "# ============================================================================\n",
    "\n",
    "# --- 1. PATHS ---\n",
    "# Update these paths to match your file locations.\n",
    "INPUT_FILE_PATH = \"/users/aranpurdy/desktop/cfps/PCA/rf/MOD_RF_Imputed.xlsx\"\n",
    "OUTPUT_DIR = \"/users/aranpurdy/desktop/TEST/IMPUTETEST\"\n",
    "OUTPUT_FILENAME = \"Ground_Truth_Imputed.xlsx\"\n",
    "\n",
    "# --- 2. SAMPLE NAMING CONVENTION ---\n",
    "# Define how your sample replicates are grouped.\n",
    "# This regex must contain ONE capturing group (...) that isolates the unique identifier for a replicate group.\n",
    "# Example: For a sample named 'TM2A2_3', the part 'TM2A2' identifies the group. The regex below captures this part.\n",
    "# Example 2: For a sample named 'Control-T2-Rep3', you might use:\n",
    "#            REPLICATE_GROUP_REGEX = r'^(Control-T2)-'\n",
    "#\n",
    "REPLICATE_GROUP_REGEX = r'^(TM2[A-Za-z]+\\d+)_'\n",
    "\n",
    "\n",
    "# --- 3. OPTIONS ---\n",
    "# Set to True to remove T0 samples before imputation.\n",
    "REMOVE_T0_SAMPLES = True\n",
    "\n",
    "# If REMOVE_T0_SAMPLES is True, list the group identifiers that correspond\n",
    "# to T0. These are the parts captured by the regex above.\n",
    "T0_GROUP_IDENTIFIERS = [\n",
    "    'TM2A1',\n",
    "    'TM2An1'\n",
    "]\n",
    "\n",
    "print(\"--- Configuration Loaded ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078aa69e-1e22-4acf-a2db-66fb4dabc360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Imputation Pipeline ---\n",
      "Successfully loaded data from 'MOD_RF_Imputed.xlsx'. Shape: (115, 51)\n",
      "\n",
      "Step 1: Removing T0 samples...\n",
      "  Removed 10 T0 columns. New shape: (115, 41)\n",
      "\n",
      "Step 2: Imputing missing values within replicate groups...\n",
      "  Identified 8 groups for imputation.\n",
      "  NaN count before imputation: 0\n",
      "  NaN count after imputation: 0\n",
      "\n",
      "Step 3: Saving processed data...\n",
      "  Successfully saved imputed data to: '/users/aranpurdy/desktop/TEST/IMPUTETEST/Ground_Truth_Imputed.xlsx'\n",
      "\n",
      "--- Pipeline Finished ---\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 2: SCRIPT LOGIC\n",
    "# A user typically does not need to edit this cell.\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "def run_imputation_pipeline(\n",
    "    input_file: str,\n",
    "    output_dir: str,\n",
    "    output_filename: str,\n",
    "    remove_t0: bool,\n",
    "    group_regex: str,\n",
    "    t0_identifiers: List[str]\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads, optionally removes T0 samples, and imputes missing values within replicate groups.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input Excel file.\n",
    "        output_dir (str): Path to the directory for saving the output.\n",
    "        output_filename (str): Name for the output Excel file.\n",
    "        remove_t0 (bool): If True, T0 samples are removed before imputation.\n",
    "        group_regex (str): Regex pattern to identify replicate groups.\n",
    "        t0_identifiers (List[str]): List of group IDs to be considered T0.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting Imputation Pipeline ---\")\n",
    "    \n",
    "    # --- 1. Load Data ---\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"ERROR: File not found at '{input_file}'.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(input_file, na_values=['', ' ', '-', '#N/A', 'NULL', 'null'])\n",
    "        print(f\"Successfully loaded data from '{os.path.basename(input_file)}'. Shape: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Excel file: {e}\")\n",
    "        return\n",
    "\n",
    "    processed_df = df.copy()\n",
    "\n",
    "    # --- 2. (Optional) Remove T0 Columns ---\n",
    "    # <<< FIX: Logic now uses the configurable regex and identifiers >>>\n",
    "    group_pattern = re.compile(group_regex, re.IGNORECASE)\n",
    "\n",
    "    if remove_t0:\n",
    "        print(\"\\nStep 1: Removing T0 samples...\")\n",
    "        columns_to_remove = []\n",
    "        for col in processed_df.columns:\n",
    "            match = group_pattern.match(str(col))\n",
    "            if match:\n",
    "                # The first captured group is the group ID\n",
    "                group_id = match.group(1)\n",
    "                if group_id in t0_identifiers:\n",
    "                    columns_to_remove.append(col)\n",
    "        \n",
    "        if columns_to_remove:\n",
    "            processed_df = processed_df.drop(columns=columns_to_remove)\n",
    "            print(f\"  Removed {len(columns_to_remove)} T0 columns. New shape: {processed_df.shape}\")\n",
    "        else:\n",
    "            print(\"  No T0 columns found to remove based on the provided identifiers.\")\n",
    "    else:\n",
    "        print(\"\\nStep 1: Skipping T0 sample removal as per configuration.\")\n",
    "\n",
    "    # --- 3. Impute Missing Values ---\n",
    "    print(\"\\nStep 2: Imputing missing values within replicate groups...\")\n",
    "    timepoint_groups = {}\n",
    "    \n",
    "    for col in processed_df.columns:\n",
    "        # <<< FIX: Use the configurable regex for grouping >>>\n",
    "        match = group_pattern.match(str(col))\n",
    "        if match:\n",
    "            group_id = match.group(1)\n",
    "            if group_id not in timepoint_groups:\n",
    "                timepoint_groups[group_id] = []\n",
    "            timepoint_groups[group_id].append(col)\n",
    "\n",
    "    if not timepoint_groups:\n",
    "        print(\"  WARNING: No replicate groups found for imputation. Check your REPLICATE_GROUP_REGEX in Cell 1.\")\n",
    "        # Save the unprocessed data if no groups are found\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        processed_df.to_excel(output_path, index=False)\n",
    "        print(f\"  Saved the unprocessed data to: '{output_path}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"  Identified {len(timepoint_groups)} groups for imputation.\")\n",
    "    nan_before = processed_df.isna().sum().sum()\n",
    "    print(f\"  NaN count before imputation: {nan_before}\")\n",
    "\n",
    "    # Perform imputation for each group\n",
    "    for group_id, cols_in_group in timepoint_groups.items():\n",
    "        if not cols_in_group:\n",
    "            continue\n",
    "        \n",
    "        group_df = processed_df[cols_in_group].apply(pd.to_numeric, errors='coerce')\n",
    "        row_means = group_df.mean(axis=1, skipna=True)\n",
    "        processed_df[cols_in_group] = group_df.T.fillna(row_means).T\n",
    "\n",
    "    nan_after = processed_df.isna().sum().sum()\n",
    "    print(f\"  NaN count after imputation: {nan_after}\")\n",
    "    if nan_after < nan_before:\n",
    "        print(\"  Imputation successfully reduced missing values.\")\n",
    "    elif nan_after > 0:\n",
    "        print(\"  NOTE: Some NaNs may remain if all replicates in a group were missing for a given row.\")\n",
    "\n",
    "    # --- 4. Save Results ---\n",
    "    print(\"\\nStep 3: Saving processed data...\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    try:\n",
    "        processed_df.to_excel(output_path, index=False)\n",
    "        print(f\"  Successfully saved imputed data to: '{output_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not save the output file. Details: {e}\")\n",
    "    \n",
    "    print(\"\\n--- Pipeline Finished ---\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# This block calls the main function with the settings from Cell 1.\n",
    "if __name__ == \"__main__\":\n",
    "    run_imputation_pipeline(\n",
    "        input_file=INPUT_FILE_PATH,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        output_filename=OUTPUT_FILENAME,\n",
    "        remove_t0=REMOVE_T0_SAMPLES,\n",
    "        group_regex=REPLICATE_GROUP_REGEX,\n",
    "        t0_identifiers=T0_GROUP_IDENTIFIERS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29ed68-1d65-4f92-8479-0c385b66c338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
