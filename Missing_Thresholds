# Apply thresholds to metabolomics data and analyze missing data patterns

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import os
warnings.filterwarnings('ignore')


# Set your file paths
INPUT_FILE_PATH = "/YOUR/INPUT/FILE/PATH"
OUTPUT_DIR = "/YOUR/OUTPUT/FILE/PATH"  

# Define what represents missing values in your dataset
MISSING_VALUE_DEFINITION = 0.001  

# FILTERING THRESHOLDS - MODIFY THESE TO ADJUST STRINGENCY
# Multiple thresholds for different filtering strategies
DETECTION_THRESHOLDS = {
    'strict': 80,      # Strict: ≥80% detection required
    'moderate': 50,    # Moderate: ≥50% detection required
    'lenient': 20      # Lenient: ≥20% detection required
}

# Define your experimental conditions
TREATMENT_SAMPLES = [
    "TM2A1_1", "TM2A1_2", "TM2A1_3", "TM2A1_4", "TM2A1_5",
    "TM2A2_1", "TM2A2_2", "TM2A2_3", "TM2A2_4", "TM2A2_5",
    "TM2A3_1", "TM2A3_2", "TM2A3_3", "TM2A3_4", "TM2A3_5",
    "TM2A4_1", "TM2A4_2", "TM2A4_3", "TM2A4_4", "TM2A4_5",
    "TM2A5_1", "TM2A5_2", "TM2A5_3", "TM2A5_4", "TM2A5_5"
]

CONTROL_SAMPLES = [
    "TM2An1_1", "TM2An1_2", "TM2An1_3", "TM2An1_4", "TM2An1_5",
    "TM2An2_1", "TM2An2_2", "TM2An2_3", "TM2An2_4", "TM2An2_5",
    "TM2An3_1", "TM2An3_2", "TM2An3_3", "TM2An3_4", "TM2An3_5",
    "TM2An4_1", "TM2An4_2", "TM2An4_3", "TM2An4_4", "TM2An4_5",
    "TM2An5_1", "TM2An5_2", "TM2An5_3", "TM2An5_4", "TM2An5_5"
]

# Experiment labels
TREATMENT_LABEL = "GFP+ (CFPS)"
CONTROL_LABEL = "Negative Control"
EXPERIMENT_NAME = "CFPS Metabolomics - GFP vs Control"

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def clean_data_matrix(data_matrix):
    """Remove non-numeric columns and convert missing values"""
    # Find numeric columns
    numeric_columns = []
    excluded_columns = []
    
    for col in data_matrix.columns:
        col_numeric = pd.to_numeric(data_matrix[col], errors='coerce')
        non_numeric_count = col_numeric.isnull().sum()
        
        if non_numeric_count > len(data_matrix) * 0.5:
            excluded_columns.append(col)
        else:
            numeric_columns.append(col)
    
    if excluded_columns:
        data_matrix = data_matrix[numeric_columns]
    
    return data_matrix

def convert_missing_values(data_matrix, missing_value):
    """Convert user-defined missing values to NaN"""
    # Convert to numeric
    data_numeric = data_matrix.copy()
    for col in data_numeric.columns:
        data_numeric[col] = pd.to_numeric(data_numeric[col], errors='coerce')
    
    # Convert missing values to NaN
    if isinstance(missing_value, (int, float)):
        missing_mask = np.abs(data_numeric - missing_value) < 1e-10
    else:
        missing_mask = data_numeric == missing_value
    
    data_numeric = data_numeric.mask(missing_mask)
    
    return data_numeric

def analyze_sample_classification(sample_names, treatment_samples, control_samples):
    """Classify samples and create sample info dataframe"""
    # Find treatment and control samples
    found_treatment = [s for s in treatment_samples if s in sample_names]
    found_control = [s for s in control_samples if s in sample_names]
    
    if len(found_treatment) == 0 or len(found_control) == 0:
        print("❌ ERROR: Could not find both treatment and control samples!")
        return None
    
    # Create sample info
    all_samples = found_treatment + found_control
    conditions = ['Treatment'] * len(found_treatment) + ['Control'] * len(found_control)
    
    return found_treatment, found_control, all_samples, conditions

def calculate_missing_statistics(data_matrix, treatment_indices, control_indices):
    """Calculate missing value statistics by condition"""
    # Overall missing
    missing_per_metabolite = (data_matrix.isnull().sum(axis=1) / data_matrix.shape[1]) * 100
    missing_per_sample = (data_matrix.isnull().sum(axis=0) / data_matrix.shape[0]) * 100
    overall_missing = (data_matrix.isnull().sum().sum() / (data_matrix.shape[0] * data_matrix.shape[1])) * 100
    
    # Condition-specific missing
    treatment_data = data_matrix.iloc[:, treatment_indices]
    control_data = data_matrix.iloc[:, control_indices]
    
    missing_treatment = (treatment_data.isnull().sum(axis=1) / treatment_data.shape[1]) * 100
    missing_control = (control_data.isnull().sum(axis=1) / control_data.shape[1]) * 100
    
    return missing_per_metabolite, missing_treatment, missing_control, overall_missing

def apply_multiple_threshold_filtering(missing_treatment, missing_control, missing_overall, data_matrix):
    """Apply multiple filtering thresholds and return filtered datasets"""
    filtered_datasets = {}
    
    for threshold_name, detection_threshold in DETECTION_THRESHOLDS.items():
        # Convert detection threshold to missing threshold
        missing_threshold = 100 - detection_threshold
        
        # Condition-aware rule (detection in either condition)
        treatment_pass = missing_treatment <= missing_threshold
        control_pass = missing_control <= missing_threshold
        condition_aware_keep = treatment_pass | control_pass
        
        # Use condition-aware filtering
        final_keep = condition_aware_keep
        
        filtered_datasets[threshold_name] = {
            'data_matrix': data_matrix,
            'keep_mask': final_keep,
            'stats': {
                'total_metabolites': final_keep.sum(),
                'detection_threshold': detection_threshold
            }
        }
    
    return filtered_datasets

def create_visualizations(missing_per_metabolite, sample_info, filtered_datasets, data_matrix, 
                         treatment_indices, control_indices, output_dir):
    """Create publication-ready visualizations"""
    print("Creating visualizations...")
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # 1. Missing distribution
    axes[0, 0].hist(missing_per_metabolite, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, 0].set_title('Distribution of Missing Values per Metabolite')
    axes[0, 0].set_xlabel('Missing Percentage (%)')
    axes[0, 0].set_ylabel('Number of Metabolites')
    
    # 2. Missing by condition
    sample_info.boxplot(column='Missing_Percent', by='Condition', ax=axes[0, 1])
    axes[0, 1].set_title('Missing Values by Condition')
    
    # 3. Threshold comparison
    threshold_names = list(DETECTION_THRESHOLDS.keys())
    metabolite_counts = [filtered_datasets[name]['stats']['total_metabolites'] for name in threshold_names]
    
    x = np.arange(len(threshold_names))
    
    axes[0, 2].bar(x, metabolite_counts, alpha=0.7, color='steelblue')
    axes[0, 2].set_xlabel('Detection Threshold')
    axes[0, 2].set_ylabel('Number of Metabolites')
    axes[0, 2].set_title('Metabolites Retained by Threshold')
    axes[0, 2].set_xticks(x)
    axes[0, 2].set_xticklabels([f"{name}\n({DETECTION_THRESHOLDS[name]}%)" for name in threshold_names])
    
    # Add value labels on bars
    for i, count in enumerate(metabolite_counts):
        axes[0, 2].text(i, count + 2, str(count), ha='center', va='bottom')
    
    # 4. Histogram of missing values per sample
    axes[1, 0].hist(sample_info['Missing_Percent'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
    axes[1, 0].set_title('Distribution of Missing Values per Sample')
    axes[1, 0].set_xlabel('Missing Percentage (%)')
    axes[1, 0].set_ylabel('Number of Samples')
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].set_xlim(0, 100)
    
    # Add statistics as text
    min_missing = sample_info['Missing_Percent'].min()
    max_missing = sample_info['Missing_Percent'].max()
    mean_missing = sample_info['Missing_Percent'].mean()
    axes[1, 0].text(0.02, 0.98, f'Range: {min_missing:.1f}% - {max_missing:.1f}%\nMean: {mean_missing:.1f}%', 
                   transform=axes[1, 0].transAxes, verticalalignment='top', 
                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    # 5. Detection thresholds vs metabolite count
    thresholds = list(range(10, 100, 10))
    counts = []
    
    # Get treatment and control missing data
    treatment_data = data_matrix.iloc[:, treatment_indices]
    control_data = data_matrix.iloc[:, control_indices]
    missing_treatment = (treatment_data.isnull().sum(axis=1) / treatment_data.shape[1]) * 100
    missing_control = (control_data.isnull().sum(axis=1) / control_data.shape[1]) * 100
    
    for thresh in thresholds:
        missing_thresh = 100 - thresh
        treatment_pass = missing_treatment <= missing_thresh
        control_pass = missing_control <= missing_thresh
        condition_aware_keep = treatment_pass | control_pass
        keep_count = condition_aware_keep.sum()
        counts.append(keep_count)
    
    axes[1, 1].plot(thresholds, counts, 'o-', linewidth=2, markersize=6, color='steelblue')
    axes[1, 1].set_xlabel('Detection Threshold (%)')
    axes[1, 1].set_ylabel('Metabolites Retained')
    axes[1, 1].set_title('Metabolites Retained vs Detection Threshold')
    axes[1, 1].grid(True, alpha=0.3)
    
    # Mark our chosen thresholds
    for name, thresh in DETECTION_THRESHOLDS.items():
        actual_count = filtered_datasets[name]['stats']['total_metabolites']
        axes[1, 1].scatter(thresh, actual_count, s=100, c='red', zorder=5)
        axes[1, 1].annotate(f'{name}\n({actual_count})', (thresh, actual_count), 
                          xytext=(5, 10), textcoords='offset points', fontsize=8, ha='center')
    
    # 6. Sample-wise missing distribution
    axes[1, 2].scatter(range(len(sample_info)), sample_info['Missing_Percent'], 
                      c=['red' if cond == 'Treatment' else 'blue' for cond in sample_info['Condition']],
                      alpha=0.7)
    axes[1, 2].set_xlabel('Sample Index')
    axes[1, 2].set_ylabel('Missing Percentage (%)')
    axes[1, 2].set_title('Missing Values per Sample')
    axes[1, 2].legend(['Treatment', 'Control'])
    
    plt.tight_layout()
    
    # Save to output directory
    output_path = os.path.join(output_dir, 'missing_data_analysis.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.show()
    print(f"   ✅ missing_data_analysis.png")

def save_results(filtered_datasets, output_dir):
    """Save the filtered metabolite datasets and threshold comparison"""
    print(f"\n💾 SAVING RESULTS:")
    print("=" * 50)
    
    # Save metabolite datasets for each threshold
    for threshold_name, dataset_info in filtered_datasets.items():
        filename = f'metabolites_for_imputation_{threshold_name}_threshold.xlsx'
        filepath = os.path.join(output_dir, filename)
        
        # Get the filtered metabolites
        filtered_metabolites = dataset_info['keep_mask']
        
        # Create dataset with metabolite names + all original sample data
        output_data = dataset_info['data_matrix'].loc[filtered_metabolites].reset_index()
        
        # Save the metabolite data
        output_data.to_excel(filepath, index=False)
        
        print(f"   ✅ {filename} ({filtered_metabolites.sum()} metabolites)")
    
    # Save threshold comparison summary
    threshold_comparison = pd.DataFrame({
        'Threshold_Name': list(DETECTION_THRESHOLDS.keys()),
        'Detection_Percent_Required': list(DETECTION_THRESHOLDS.values()),
        'Total_Metabolites_Kept': [filtered_datasets[name]['stats']['total_metabolites'] for name in DETECTION_THRESHOLDS.keys()]
    })
    
    comparison_filepath = os.path.join(output_dir, 'threshold_comparison.xlsx')
    threshold_comparison.to_excel(comparison_filepath, index=False)
    print(f"   ✅ threshold_comparison.xlsx")

# ============================================================================
# MAIN ANALYSIS FUNCTION
# ============================================================================

def main():
    print("=" * 60)
    print(f"  {EXPERIMENT_NAME}")
    print("=" * 60)
    
    # Create output directory if it doesn't exist
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    
    # Read data
    try:
        metabolite_data = pd.read_excel(INPUT_FILE_PATH)
    except Exception as e:
        print(f"❌ Error reading file: {e}")
        return
    
    # Prepare data matrix
    metabolite_names = metabolite_data.iloc[:, 0]
    data_matrix = metabolite_data.iloc[:, 1:]
    data_matrix.index = metabolite_names
    
    # Clean data
    data_matrix = clean_data_matrix(data_matrix)
    
    # Convert missing values
    data_matrix = convert_missing_values(data_matrix, MISSING_VALUE_DEFINITION)
    
    # Classify samples
    sample_names = data_matrix.columns.tolist()
    result = analyze_sample_classification(sample_names, TREATMENT_SAMPLES, CONTROL_SAMPLES)
    
    if result is None:
        return
    
    treatment_samples, control_samples, all_samples, conditions = result
    
    # Get sample indices
    treatment_indices = [data_matrix.columns.get_loc(s) for s in treatment_samples]
    control_indices = [data_matrix.columns.get_loc(s) for s in control_samples]
    
    # Calculate missing statistics
    missing_per_metabolite, missing_treatment, missing_control, overall_missing = calculate_missing_statistics(
        data_matrix, treatment_indices, control_indices
    )
    
    # Apply multiple threshold filtering
    filtered_datasets = apply_multiple_threshold_filtering(
        missing_treatment, missing_control, missing_per_metabolite, data_matrix
    )
    
    # Create sample info dataframe
    sample_missing_percentages = []
    for sample in all_samples:
        if sample in data_matrix.columns:
            sample_missing_pct = (data_matrix[sample].isnull().sum() / len(data_matrix)) * 100
            sample_missing_percentages.append(sample_missing_pct)
        else:
            sample_missing_percentages.append(np.nan)
    
    sample_info = pd.DataFrame({
        'Sample': all_samples,
        'Condition': conditions,
        'Missing_Percent': sample_missing_percentages
    })
    
    # Print summary
    print(f"\n📊 EXPERIMENT SUMMARY:")
    print(f"   Total metabolites: {len(data_matrix)}")
    print(f"   Treatment samples: {len(treatment_samples)}")
    print(f"   Control samples: {len(control_samples)}")
    print(f"   Overall missing: {overall_missing:.2f}%")
    
    print(f"\n🎯 THRESHOLD-BASED FILTERING RESULTS:")
    for threshold_name, dataset_info in filtered_datasets.items():
        stats = dataset_info['stats']
        print(f"   {threshold_name.upper()} ({DETECTION_THRESHOLDS[threshold_name]}% detection):")
        print(f"      • Total metabolites: {stats['total_metabolites']}")
    
    # Save results
    save_results(filtered_datasets, OUTPUT_DIR)
    
    # Create visualizations
    create_visualizations(missing_per_metabolite, sample_info, filtered_datasets, 
                         data_matrix, treatment_indices, control_indices, OUTPUT_DIR)
    
    print(f"\n🎉 ANALYSIS COMPLETE!")
    print(f"📁 Output files:")
    print(f"   • metabolites_for_imputation_strict_threshold.xlsx")
    print(f"   • metabolites_for_imputation_moderate_threshold.xlsx") 
    print(f"   • metabolites_for_imputation_lenient_threshold.xlsx")
    print(f"   • threshold_comparison.xlsx")
    print(f"   • missing_data_analysis.png")

# ============================================================================
# RUN ANALYSIS
# ============================================================================

if __name__ == "__main__":
    main()
