{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50782888-57e4-4e40-9a74-735389ef5b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuration Loaded ---\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 1: CONFIGURATION\n",
    "# This cell contains all the settings a user needs to change.\n",
    "# ============================================================================\n",
    "\n",
    "# --- 1. File Paths ---\n",
    "# Update these paths to match your file locations.\n",
    "INPUT_FILE_PATH = \"/PATH/TO/INPUT/FILE\"\n",
    "OUTPUT_DIR = \"PATH/TO/OUTPUT/DIR\"\n",
    "\n",
    "# --- 2. Data Exclusions ---\n",
    "# List any metabolites to remove from the analysis. Use an empty list [] if none.\n",
    "METABOLITES_TO_EXCLUDE = ['9-methylanthracene']\n",
    "\n",
    "# --- 3. Sample Naming Convention ---\n",
    "# Define your experimental conditions and how to identify them using regular expressions.\n",
    "# The key is the name of the condition (e.g., '+GFP').\n",
    "# The value is a regex pattern that identifies samples belonging to that condition.\n",
    "# The regex MUST include a named group `(?P<timepoint>\\d+)` to capture the timepoint identifier.\n",
    "CONDITIONS = {\n",
    "    '+GFP': r'TM2A(?P<timepoint>\\d+)_',\n",
    "    '-GFP': r'TM2An(?P<timepoint>\\d+)_'\n",
    "}\n",
    "\n",
    "# --- 4. Group & Timepoint Mapping ---\n",
    "# Map the condition names above to numerical labels for the PLS-DA model.\n",
    "# Typically, this is 0 and 1.\n",
    "GROUP_LABELS = {\n",
    "    '+GFP': 0,\n",
    "    '-GFP': 1\n",
    "}\n",
    "\n",
    "# Map the captured timepoint identifier (from the regex) to a display name for plots.\n",
    "TIMEPOINT_MAP = {\n",
    "    '1': '0h',\n",
    "    '2': '0.5h',\n",
    "    '3': '2h',\n",
    "    '4': '5h',\n",
    "    '5': '10h'\n",
    "}\n",
    "\n",
    "# List the display names in the order you want them to appear in plot legends.\n",
    "TIMEPOINT_PLOT_ORDER = ['0h', '0.5h', '2h', '5h', '10h']\n",
    "\n",
    "\n",
    "# --- 5. PLS-DA & Plotting Parameters ---\n",
    "# Maximum number of latent variables (components) to test during cross-validation.\n",
    "MAX_PLS_COMPONENTS = 10\n",
    "# VIP score threshold to draw on the VIP plot.\n",
    "VIP_THRESHOLD = 1.0\n",
    "# Number of top metabolites to show on the VIP bar plot.\n",
    "TOP_N_VIP = 20\n",
    "# Number of top metabolites (by VIP score) to label on the loadings plot.\n",
    "TOP_N_LOADINGS = 15\n",
    "\n",
    "print(\"--- Configuration Loaded ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f058020-a6bd-4774-89ce-e0745764b24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting PLS-DA Pipeline ---\n",
      "✓ Loaded data from 'MOD_RF_Imputed.xlsx'. Shape: (115, 50)\n",
      "  - Removed metabolite: '9-methylanthracene'\n",
      "✓ Parsed 50 samples into 2 conditions.\n",
      "\n",
      "Applying Pareto scaling...\n",
      "\n",
      "Determining optimal number of components via Leave-One-Out CV...\n",
      "  - Components: 1, CV Accuracy: 0.540\n",
      "  - Components: 2, CV Accuracy: 0.740\n",
      "  - Components: 3, CV Accuracy: 0.820\n",
      "  - Components: 4, CV Accuracy: 0.820\n",
      "  - Components: 5, CV Accuracy: 0.860\n",
      "  - Components: 6, CV Accuracy: 0.880\n",
      "  - Components: 7, CV Accuracy: 0.860\n",
      "  - Components: 8, CV Accuracy: 0.920\n",
      "  - Components: 9, CV Accuracy: 0.880\n",
      "  - Components: 10, CV Accuracy: 0.880\n",
      "✓ Optimal number of components found: 8\n",
      "\n",
      "Fitting final PLS-DA model...\n",
      "✓ VIP scores calculated and saved.\n",
      "\n",
      "Creating visualizations...\n",
      "✓ Scores plot saved.\n",
      "✓ Loadings plot saved.\n",
      "✓ VIP scores bar plot saved.\n",
      "\n",
      "--- Pipeline Finished ---\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Cell 2: SCRIPT LOGIC\n",
    "# A user typically does not need to edit this cell.\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import re\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def normalize_metabolite_name(name):\n",
    "    if not isinstance(name, str): return name\n",
    "    return name.lower().replace(\"'\", \"\").replace('\"', \"\").strip()\n",
    "\n",
    "def pareto_scale(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0, ddof=1)\n",
    "    std[std == 0] = 1e-8 # Avoid division by zero\n",
    "    return (data - mean) / np.sqrt(std)\n",
    "\n",
    "def calculate_explained_variance(X_scaled, scores):\n",
    "    total_variance_X = np.sum(np.var(X_scaled, axis=0))\n",
    "    explained_variances = [np.var(scores[:, i]) / total_variance_X for i in range(scores.shape[1])]\n",
    "    return np.array(explained_variances)\n",
    "\n",
    "def add_confidence_ellipse(ax, x, y, **kwargs):\n",
    "    if len(x) < 3: return\n",
    "    cov = np.cov(x, y)\n",
    "    if np.any(~np.isfinite(cov)): return\n",
    "    pearson = cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    if not np.isfinite(pearson): return\n",
    "    ell_radius_x, ell_radius_y = np.sqrt(1 + pearson), np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2, **kwargs)\n",
    "    scale_x, scale_y = np.sqrt(cov[0, 0]) * 2.0, np.sqrt(cov[1, 1]) * 2.0\n",
    "    mean_x, mean_y = np.mean(x), np.mean(y)\n",
    "    transf = transforms.Affine2D().rotate_deg(45).scale(scale_x, scale_y).translate(mean_x, mean_y)\n",
    "    ellipse.set_transform(transf + ax.transData); ax.add_patch(ellipse)\n",
    "\n",
    "def calculate_vip(model):\n",
    "    t, w, q = model.x_scores_, model.x_weights_, model.y_loadings_\n",
    "    p, h = w.shape\n",
    "    vips = np.zeros((p,))\n",
    "    s = np.diag(t.T @ t @ q.T @ q).reshape(h, -1)\n",
    "    total_s = np.sum(s)\n",
    "    for i in range(p):\n",
    "        weight = np.array([(w[i,j] / np.linalg.norm(w[:,j]))**2 for j in range(h)])\n",
    "        vips[i] = np.sqrt(p * (s.T @ weight).item() / total_s)\n",
    "    return vips\n",
    "\n",
    "# --- Main Analysis Pipeline ---\n",
    "def run_plsda_analysis(config):\n",
    "    \"\"\"Loads data, runs PLS-DA, and generates plots based on the config dictionary.\"\"\"\n",
    "    print(\"--- Starting PLS-DA Pipeline ---\")\n",
    "    os.makedirs(config['output_dir'], exist_ok=True)\n",
    "    \n",
    "    # 1. Load and Prepare Data\n",
    "    try:\n",
    "        df = pd.read_excel(config['input_file'], sheet_name=0, index_col=0)\n",
    "        df.index = df.index.map(normalize_metabolite_name)\n",
    "        print(f\"✓ Loaded data from '{os.path.basename(config['input_file'])}'. Shape: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ ERROR: Could not load input file. Details: {e}\"); return\n",
    "\n",
    "    # Exclude specified metabolites\n",
    "    for met in config['metabolites_to_exclude']:\n",
    "        met_norm = normalize_metabolite_name(met)\n",
    "        if met_norm in df.index:\n",
    "            df = df.drop(met_norm)\n",
    "            print(f\"  - Removed metabolite: '{met}'\")\n",
    "\n",
    "    # 2. Dynamically Parse Sample Information using Config\n",
    "    all_sample_info = []\n",
    "    for condition_name, pattern in config['conditions'].items():\n",
    "        regex = re.compile(pattern, re.IGNORECASE)\n",
    "        for col in df.columns:\n",
    "            match = regex.search(str(col))\n",
    "            if match:\n",
    "                try:\n",
    "                    tp_id = match.group('timepoint')\n",
    "                    tp_name = config['timepoint_map'].get(tp_id, f\"ID:{tp_id}\")\n",
    "                    all_sample_info.append({\n",
    "                        'Sample': col, 'Condition': condition_name,\n",
    "                        'TimepointID': tp_id, 'TimepointName': tp_name\n",
    "                    })\n",
    "                except IndexError:\n",
    "                    print(f\"✗ WARNING: Regex '{pattern}' is missing the named group '(?P<timepoint>...)'.\")\n",
    "    \n",
    "    sample_info_df = pd.DataFrame(all_sample_info)\n",
    "    if sample_info_df.empty:\n",
    "        print(\"✗ ERROR: No samples matched the patterns in the CONDITIONS configuration. Halting analysis.\"); return\n",
    "\n",
    "    print(f\"✓ Parsed {len(sample_info_df)} samples into {len(sample_info_df['Condition'].unique())} conditions.\")\n",
    "\n",
    "    # 3. Create X and y matrices for PLS-DA\n",
    "    X_df = df[sample_info_df['Sample']].T\n",
    "    X = X_df.values\n",
    "    y = sample_info_df['Condition'].map(config['group_labels']).values\n",
    "    metabolite_names = X_df.columns.tolist()\n",
    "\n",
    "    print(\"\\nApplying Pareto scaling...\")\n",
    "    X_scaled = pareto_scale(X)\n",
    "\n",
    "    # 4. Cross-validation to find optimal number of components\n",
    "    print(\"\\nDetermining optimal number of components via Leave-One-Out CV...\")\n",
    "    max_components = min(config['max_pls_components'], X_scaled.shape[0] - 1, X_scaled.shape[1])\n",
    "    cv_scores = []\n",
    "    for n_comp in range(1, max_components + 1):\n",
    "        pls = PLSRegression(n_components=n_comp, scale=False)\n",
    "        y_pred_cv = cross_val_predict(pls, X_scaled, y, cv=LeaveOneOut())\n",
    "        accuracy = accuracy_score(y, (y_pred_cv > 0.5).astype(int))\n",
    "        cv_scores.append(accuracy)\n",
    "        print(f\"  - Components: {n_comp}, CV Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    optimal_components = np.argmax(cv_scores) + 1\n",
    "    print(f\"✓ Optimal number of components found: {optimal_components}\")\n",
    "\n",
    "    # 5. Fit Final Model and Extract Results\n",
    "    print(\"\\nFitting final PLS-DA model...\")\n",
    "    pls_da = PLSRegression(n_components=optimal_components, scale=False)\n",
    "    pls_da.fit(X_scaled, y)\n",
    "    scores, loadings = pls_da.x_scores_, pls_da.x_loadings_\n",
    "    vip_scores = calculate_vip(pls_da)\n",
    "    vip_df = pd.DataFrame({'Metabolite': metabolite_names, 'VIP': vip_scores}).sort_values('VIP', ascending=False)\n",
    "    vip_df.to_excel(os.path.join(config['output_dir'], 'vip_scores.xlsx'), index=False)\n",
    "    print(\"✓ VIP scores calculated and saved.\")\n",
    "\n",
    "    # 6. Generate Visualizations\n",
    "    print(\"\\nCreating visualizations...\")\n",
    "    explained_variance_ratio = calculate_explained_variance(X_scaled, scores)\n",
    "    \n",
    "    # --- Scores Plot ---\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    colors = plt.cm.plasma_r(np.linspace(0.1, 0.9, len(config['timepoint_plot_order'])))\n",
    "    color_dict = {name: color for name, color in zip(config['timepoint_plot_order'], colors)}\n",
    "\n",
    "    for tp_name in config['timepoint_plot_order']:\n",
    "        for condition, marker in {'+GFP': 'o', '-GFP': 's'}.items():\n",
    "            mask = (sample_info_df['TimepointName'] == tp_name) & (sample_info_df['Condition'] == condition)\n",
    "            if mask.any():\n",
    "                ax.scatter(scores[mask, 0], scores[mask, 1], color=color_dict[tp_name], marker=marker,\n",
    "                            s=150, alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "    \n",
    "    ellipse_handles = []\n",
    "    for cond_name, color in [('+GFP', 'blue'), ('-GFP', 'red')]:\n",
    "        mask = sample_info_df['Condition'] == cond_name\n",
    "        if mask.sum() > 2:\n",
    "            add_confidence_ellipse(ax, scores[mask, 0], scores[mask, 1], facecolor='none', edgecolor=color, linestyle='--', linewidth=2)\n",
    "            ellipse_handles.append(Line2D([0], [0], color=color, lw=2, linestyle='--', label=f'{cond_name} 95% CI'))\n",
    "\n",
    "    legend_timepoints = [Line2D([0], [0], marker='o', color='w', label=name, markerfacecolor=color_dict[name], markersize=12) for name in config['timepoint_plot_order']]\n",
    "    legend_conditions = [Line2D([0], [0], marker=m, color='w', label=c, markerfacecolor='grey', markeredgecolor='black', markersize=12) for c, m in {'+GFP': 'o', '-GFP': 's'}.items()]\n",
    "    ax.legend(handles=legend_timepoints + legend_conditions + ellipse_handles, title=\"Legend\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    ax.set_xlabel(f'LV1 ({explained_variance_ratio[0]:.1%} variance)'); ax.set_ylabel(f'LV2 ({explained_variance_ratio[1]:.1%} variance)')\n",
    "    ax.set_title('PLS-DA Scores Plot'); ax.grid(True, alpha=0.3); ax.axhline(0, c='grey', ls='--'); ax.axvline(0, c='grey', ls='--')\n",
    "    plt.savefig(os.path.join(config['output_dir'], 'plsda_scores_plot.pdf'), dpi=300, bbox_inches='tight'); plt.close(fig)\n",
    "    print(\"✓ Scores plot saved.\")\n",
    "\n",
    "    # --- Loadings Plot ---\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    scatter = ax.scatter(loadings[:, 0], loadings[:, 1], c=vip_scores, cmap='hot', s=80, alpha=0.7, edgecolors='black')\n",
    "    top_vips = vip_df.head(config['top_n_loadings'])\n",
    "    for _, row in top_vips.iterrows():\n",
    "        met_idx = metabolite_names.index(row['Metabolite'])\n",
    "        ax.text(loadings[met_idx, 0], loadings[met_idx, 1], row['Metabolite'], fontsize=8)\n",
    "    cbar = plt.colorbar(scatter, ax=ax); cbar.set_label('VIP Score')\n",
    "    ax.set_xlabel('LV1 Loadings'); ax.set_ylabel('LV2 Loadings'); ax.set_title('PLS-DA Loadings Plot'); ax.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(config['output_dir'], 'plsda_loadings_plot.pdf'), dpi=300, bbox_inches='tight'); plt.close(fig)\n",
    "    print(\"✓ Loadings plot saved.\")\n",
    "\n",
    "    # --- VIP Score Barplot ---\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    vip_top = vip_df.head(config['top_n_vip'])\n",
    "    ax.barh(vip_top['Metabolite'], vip_top['VIP'], color='steelblue'); ax.invert_yaxis()\n",
    "    ax.set_xlabel('VIP Score'); ax.set_title(f\"Top {config['top_n_vip']} Metabolites by VIP Score\")\n",
    "    ax.axvline(x=config['vip_threshold'], color='red', linestyle='--', label=f\"VIP > {config['vip_threshold']} Threshold\"); ax.legend()\n",
    "    plt.savefig(os.path.join(config['output_dir'], 'vip_scores_barplot.pdf'), dpi=300, bbox_inches='tight'); plt.close(fig)\n",
    "    print(\"✓ VIP scores bar plot saved.\")\n",
    "    \n",
    "    print(\"\\n--- Pipeline Finished ---\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# This block creates a configuration dictionary and runs the pipeline.\n",
    "if __name__ == \"__main__\":\n",
    "    config_dict = {\n",
    "        \"input_file\": INPUT_FILE_PATH,\n",
    "        \"output_dir\": OUTPUT_DIR,\n",
    "        \"metabolites_to_exclude\": METABOLITES_TO_EXCLUDE,\n",
    "        \"conditions\": CONDITIONS,\n",
    "        \"group_labels\": GROUP_LABELS,\n",
    "        \"timepoint_map\": TIMEPOINT_MAP,\n",
    "        \"timepoint_plot_order\": TIMEPOINT_PLOT_ORDER,\n",
    "        \"max_pls_components\": MAX_PLS_COMPONENTS,\n",
    "        \"vip_threshold\": VIP_THRESHOLD,\n",
    "        \"top_n_vip\": TOP_N_VIP,\n",
    "        \"top_n_loadings\": TOP_N_LOADINGS\n",
    "    }\n",
    "    run_plsda_analysis(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835297b5-4a5d-4fee-b7d6-bc49c89759b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
